{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d095447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81f40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./cifar10.tgz\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "download_url(dataset_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96844a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s5/hfv0b_kn3_l6vxt06f1x67q80000gn/T/ipykernel_804/2472178392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cifar10.tgz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2019\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0;31m# Extract directories with a safe mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2432\u001b[0m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2434\u001b[0;31m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFHeaderError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_zeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mfromtarfile\u001b[0;34m(cls, tarfile)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \"\"\"\n\u001b[1;32m   1104\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mfrombuf\u001b[0;34m(cls, buf, encoding, errors)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mnti\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mnts\u001b[0;34m(s, encoding, errors)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "    tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6db5de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cat',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'automobile']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './data/cifar10/'\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129bb3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airplane_files = os.listdir(data_dir + 'train/airplane')\n",
    "len(airplane_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4beafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aede021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 50000\n",
       "    Root Location: ./data/cifar10/train\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageFolder(data_dir+'train', transform = ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8edcb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d80525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):\n",
    "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0caf5c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  automobile (1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(*dataset[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b49bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e342570>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bbbf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000\n",
    "batch_size=128\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d6b9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size = 128\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97633933",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(nn.Conv2d(3,8,kernel_size = 3, stride=1, padding=1), nn.MaxPool2d(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c9c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape:  torch.Size([128, 3, 32, 32])\n",
      "out.shape:  torch.Size([128, 8, 16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradiptomondal/miniforge3/envs/tf/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-4zyfwhmc/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_dl:\n",
    "    print('images.shape: ', images.shape)\n",
    "    out = simple_model(images)\n",
    "    print('out.shape: ', out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a9c538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = self.accuracy(out, labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "    def accuracy(self,outputs,labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a4d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3,32,kernel_size = 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e47a31e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cifar10(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cifar10()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4db5b567",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'cifar10' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s5/hfv0b_kn3_l6vxt06f1x67q80000gn/T/ipykernel_804/3776860707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'cifar10' object is not iterable"
     ]
    }
   ],
   "source": [
    "for x in model:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00dbd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "out.shape: torch.Size([128, 10])\n",
      "out[0]: tensor([ 0.0494,  0.0320, -0.0174,  0.0410, -0.0128,  0.0312, -0.0338, -0.0229,\n",
      "         0.0299,  0.0287], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    print('out[0]:', out[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a173a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        print(1)\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e725003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "a = torch.tensor((2,3))\n",
    "isinstance(model, (list, tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1707a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cifar10(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e347847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8d6a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(cifar10(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b0ee52d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.302766799926758, 'val_acc': 0.0995289534330368}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "894a8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e0112f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 1.7714, val_loss: 1.3878, val_acc: 0.4677\n",
      "Epoch [1], train_loss: 1.2786, val_loss: 1.0988, val_acc: 0.6059\n",
      "Epoch [2], train_loss: 1.0117, val_loss: 0.8919, val_acc: 0.6870\n",
      "Epoch [3], train_loss: 0.8254, val_loss: 0.8176, val_acc: 0.7095\n",
      "Epoch [4], train_loss: 0.6874, val_loss: 0.7919, val_acc: 0.7316\n",
      "Epoch [5], train_loss: 0.5667, val_loss: 0.7335, val_acc: 0.7438\n",
      "Epoch [6], train_loss: 0.4561, val_loss: 0.7415, val_acc: 0.7510\n",
      "Epoch [7], train_loss: 0.3593, val_loss: 0.7760, val_acc: 0.7600\n",
      "Epoch [8], train_loss: 0.2798, val_loss: 0.8296, val_acc: 0.7568\n",
      "Epoch [9], train_loss: 0.2136, val_loss: 0.9356, val_acc: 0.7579\n"
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184d57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
